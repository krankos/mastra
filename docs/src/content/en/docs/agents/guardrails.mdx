---
title: "Guardrails | Agents | Mastra Docs"
description: "Learn how to implement guardrails using input and output processors to secure and control AI interactions."
---

# Guardrails

Processors allow you to implement guardrails by intercepting, modifying, validating, sanitizing, or filtering messages at different stages of the AI interaction. Agents can use processors as both `inputProcessors` (applied before messages reach the language model) and `outputProcessors` (applied to AI responses before they're returned to users). This is useful for implementing comprehensive guardrails, content moderation, prompt injection prevention, response sanitization, message transformation, and security controls.

Processors operate on the messages in your conversation thread. They can modify, filter, or validate content, and even abort the request entirely if certain conditions are met.

## Input processors

Input processors are applied to user messages before they reach the language model. Mastra provides several built-in input processors for common use cases:

### `UnicodeNormalizer`

This processor normalizes Unicode text to ensure consistent formatting and remove potentially problematic characters.

```typescript {6-9} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { UnicodeNormalizer } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new UnicodeNormalizer({
      stripControlChars: true,
      collapseWhitespace: true,
    })
  ],
});
```

Available options:
- `stripControlChars`: Remove control characters (default: false)
- `preserveEmojis`: Keep emojis intact (default: true)
- `collapseWhitespace`: Collapse multiple spaces/newlines (default: true)
- `trim`: Remove leading/trailing whitespace (default: true)

### `ModerationProcessor`

This processor provides content moderation using an LLM to detect inappropriate content across multiple categories.

```typescript {6-11} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { ModerationProcessor } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new ModerationProcessor({
      model: openai("gpt-4.1-nano"),
      threshold: 0.7,
      strategy: 'block',
      categories: ['hate', 'harassment', 'violence']
    })
  ],
});
```

Available options:
- `model`: Language model for moderation analysis (required)
- `categories`: Array of categories to check (default: ['hate','hate/threatening','harassment','harassment/threatening','self-harm','self-harm/intent','self-harm/instructions','sexual','sexual/minors','violence','violence/graphic'])
- `threshold`: Confidence threshold for flagging (0-1, default: 0.5)
- `strategy`: Action when content is flagged (default: 'block')
- `customInstructions`: Custom instructions for the moderation agent

Strategies available:
- `block`: Reject the request with an error (default)
- `warn`: Log warning but allow content through
- `filter`: Remove flagged messages but continue processing

### `PromptInjectionDetector`

This processor detects and prevents prompt injection attacks, jailbreaks, and system manipulation attempts.

```typescript {6-11} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { PromptInjectionDetector } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new PromptInjectionDetector({
      model: openai("gpt-4.1-nano"),
      threshold: 0.8,
      strategy: 'rewrite',
      detectionTypes: ['injection', 'jailbreak', 'system-override'],
    })
  ],
});
```

Available options:
- `model`: Language model for injection detection (required)
- `detectionTypes`: Array of injection types to detect (default: ['injection', 'jailbreak', 'system-override'])
- `threshold`: Confidence threshold for flagging (0-1, default: 0.7)
- `strategy`: Action when injection is detected (default: 'block')
- `instructions`: Custom detection instructions for the agent
- `includeScores`: Whether to include confidence scores in logs (default: false)

Strategies available:
- `block`: Reject the request (default)
- `warn`: Log warning but allow through
- `filter`: Remove flagged messages
- `rewrite`: Attempt to neutralize the injection while preserving legitimate intent

### `PIIDetector`

This processor detects and optionally redacts personally identifiable information (PII) from messages.

```typescript {6-14} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { PIIDetector } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new PIIDetector({
      model: openai("gpt-4.1-nano"),
      threshold: 0.6,
      strategy: 'redact',
      detectionTypes: ['email', 'phone', 'credit-card', 'ssn', 'api-key', 'crypto-wallet', 'iban'],
      redactionMethod: 'mask',
      preserveFormat: true,
      includeDetections: true
    })
  ],
});
```

Available options:
- `model`: Language model for PII detection (required)
- `detectionTypes`: Array of PII types to detect (default: ['email', 'phone', 'credit-card', 'ssn', 'api-key', 'ip-address', 'name', 'address', 'date-of-birth', 'url', 'uuid', 'crypto-wallet', 'iban'])
- `threshold`: Confidence threshold for flagging (0-1, default: 0.6)
- `strategy`: Action when PII is detected (default: 'block')
- `redactionMethod`: How to redact PII ('mask', 'hash', 'remove', 'placeholder', default: 'mask')
- `preserveFormat`: Maintain PII structure during redaction (default: true)
- `includeDetections`: Include detection details in logs for compliance (default: false)
- `instructions`: Custom detection instructions for the agent

Strategies available:
- `block`: Reject requests containing PII (default)
- `warn`: Log warning but allow through
- `filter`: Remove messages containing PII
- `redact`: Replace PII with placeholder values

### `LanguageDetector`

This processor detects the language of incoming messages and can automatically translate them to a target language.

```typescript {6-11} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { LanguageDetector } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new LanguageDetector({
      model: openai("gpt-4o-mini"),
      targetLanguages: ['English', 'en'],
      strategy: 'translate',
      threshold: 0.8,
    })
  ],
});
```

Available options:
- `model`: Language model for detection and translation (required)
- `targetLanguages`: Array of target languages (language names or ISO codes)
- `threshold`: Confidence threshold for language detection (0-1, default: 0.7)
- `strategy`: Action when non-target language is detected (default: 'detect')
- `preserveOriginal`: Keep original content in metadata (default: true)
- `instructions`: Custom detection instructions for the agent

Strategies available:
- `detect`: Only detect language, don't translate (default)
- `translate`: Automatically translate to target language
- `block`: Reject content not in target language
- `warn`: Log warning but allow content through

## Applying multiple processors

You can chain multiple processors. They execute sequentially in the order they appear in the `inputProcessors` array. The output of one processor becomes the input for the next.

**Order matters!** Generally, it's best practice to place text normalization first, security checks next, and content modification last.

```typescript {10-15} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import {
  UnicodeNormalizer,
  ModerationProcessor,
  PromptInjectionDetector,
  PIIDetector
} from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new UnicodeNormalizer({ stripControlChars: true }),
    new PromptInjectionDetector({ model: openai("gpt-4.1-nano") }),
    new ModerationProcessor({ model: openai("gpt-4.1-nano") }),
    new PIIDetector({ model: openai("gpt-4.1-nano"), strategy: 'redact' }),
  ],
});
```

## Integration with agent methods

Input processors work with both `.generate()`, `.stream()` methods. The entire processor pipeline completes before the agent begins generating or streaming a response.

```typescript
const result = await agent.generate('Hello ****');

const stream = await agent.stream('Hello ****');
for await (const chunk of stream) {
  console.log(chunk);
}
```

If any processor calls `abort()`, the request terminates immediately and subsequent processors are not executed. The agent returns a 200 response with details about why the request was blocked.

```text
{
  // ...
  tripwire: true,
  tripwireReason: 'Content flagged for moderation. Categories: harassment. Reason: The content contains a highly offensive term used as an insult, indicating harassment.. Scores: {"hate":0.2,"harassment":0.8,"violence":0}',
  traceId: undefined
}
```

## Creating custom processors

You can create custom processors by implementing the `Processor` interface. A Processor can be used for input processing when it implements the `processInput` method.

```typescript filename="src/mastra/processors/message-length-limiter.ts" copy showLineNumbers
import type { Processor } from "@mastra/core/processors";
import type { MastraMessageV2 } from "@mastra/core/agent/message-list";
import { TripWire } from "@mastra/core/agent";

export class MessageLengthLimiter implements Processor {
  readonly name = "message-length-limiter";

  constructor(private maxLength: number = 1000) {}

  processInput({ messages, abort }: {
    messages: MastraMessageV2[];
    abort: (reason?: string) => never;
  }): MastraMessageV2[] {
    try {
      const totalLength = messages.reduce((sum, msg) => {
        return (
          sum +
          msg.content.parts
            .filter((part) => part.type === "text")
            .reduce((partSum, part) => partSum + (part as any).text.length, 0)
        );
      }, 0);

      if (totalLength > this.maxLength) {
        abort(`Message too long: ${totalLength} characters (max: ${this.maxLength})`);
      }
    } catch (error) {
      if (error instanceof TripWire) {
        throw error;
      }
      const errorMessage = error instanceof Error ? error.message : "Unknown error";
      throw new Error(`Length validation failed: ${errorMessage}`);
    }

    return messages;
  }
}
```

When creating custom processors:

- Always return the `messages` array (potentially modified)
- Use `abort(reason)` to terminate processing early. Abort is used to simulate blocking a message. errors thrown with `abort` will be an instance of TripWire. For code/application level errors, throw standard errors.
- Mutate the input messages directly, make sure to mutate both the parts and content of a message.
- Keep processors focused on a single responsibility
- If using an agent inside your processor, use a fast model, limit the size of the response from it as much as possible (every token slows down the response exponentially), and make the system prompt as concise as possible, these are both latency bottlenecks.


### Example usage

Input processors work with the `.generate()` and `.stream()` methods. The entire processor pipeline completes before the agent begins generating or streaming a response.

```typescript {6} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { MessageLengthLimiter } from "../processors/message-length-limiter";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new MessageLengthLimiter(2000)
  ]
});

// Processors also run before stream()
const stream = await testAgent.stream('Hello');

for await (const chunk of stream) {
  console.log(chunk);
}
```

## Output processors

Output processors are applied to AI responses after they are generated by the language model but before they are returned to users. This is useful for implementing response validation, content moderation, response transformation, and safety controls on AI-generated content.

Mastra provides several built-in output processors for common use cases:

### `ModerationProcessor`

This processor provides content moderation using an LLM to detect inappropriate content across multiple categories.

```typescript copy showLineNumbers {5-13}
import { ModerationProcessor } from "@mastra/core/processors";

const agent = new Agent({
  outputProcessors: [
    new ModerationProcessor({
      model: openai("gpt-4.1-nano"), // Use a fast, cost-effective model
      threshold: 0.7, // Confidence threshold for flagging
      strategy: 'block', // Block flagged content
      categories: ['hate', 'harassment', 'violence'], // Custom categories
    }),
  ],
});
```

Available options:
- `model`: Language model for moderation analysis (required)
- `categories`: Array of categories to check (default: ['hate','hate/threatening','harassment','harassment/threatening','self-harm','self-harm/intent','self-harm/instructions','sexual','sexual/minors','violence','violence/graphic'])
- `threshold`: Confidence threshold for flagging (0-1, default: 0.5)
- `strategy`: Action when content is flagged (default: 'block')
- `customInstructions`: Custom instructions for the moderation agent

Strategies available:
- `block`: Reject the response with an error (default)
- `warn`: Log warning but allow content through
- `filter`: Remove flagged messages but continue processing

### `PIIDetector`

This processor detects and optionally redacts personally identifiable information (PII) from AI responses.

```typescript copy showLineNumbers {5-14}
import { PIIDetector } from "@mastra/core/processors";

const agent = new Agent({
  outputProcessors: [
    new PIIDetector({
      model: openai("gpt-4.1-nano"),
      threshold: 0.6,
      strategy: 'redact', // Automatically redact detected PII
      detectionTypes: ['email', 'phone', 'credit-card', 'ssn', 'api-key', 'crypto-wallet', 'iban'],
      redactionMethod: 'mask', // Preserve format while masking
      preserveFormat: true, // Keep original structure in redacted values
      includeDetections: true, // Log details for compliance auditing
    }),
  ],
});
```

Available options:
- `model`: Language model for PII detection (required)
- `detectionTypes`: Array of PII types to detect (default: ['email', 'phone', 'credit-card', 'ssn', 'api-key', 'ip-address', 'name', 'address', 'date-of-birth', 'url', 'uuid', 'crypto-wallet', 'iban'])
- `threshold`: Confidence threshold for flagging (0-1, default: 0.6)
- `strategy`: Action when PII is detected (default: 'block')
- `redactionMethod`: How to redact PII ('mask', 'hash', 'remove', 'placeholder', default: 'mask')
- `preserveFormat`: Maintain PII structure during redaction (default: true)
- `includeDetections`: Include detection details in logs for compliance (default: false)
- `instructions`: Custom detection instructions for the agent

Strategies available:
- `block`: Reject responses containing PII (default)
- `warn`: Log warning but allow through
- `filter`: Remove messages containing PII
- `redact`: Replace PII with placeholder values

### `BatchPartsProcessor`

This processor batches multiple stream parts together to reduce the frequency of emissions, useful for reducing network overhead or improving user experience.

```typescript copy showLineNumbers {5-12}
import { BatchPartsProcessor } from "@mastra/core/processors";

const agent = new Agent({
  outputProcessors: [
    new BatchPartsProcessor({
      maxBatchSize: 5, // Maximum parts to batch together
      maxWaitTime: 100, // Maximum time to wait before emitting (ms)
      emitOnNonText: true, // Emit immediately on non-text parts
    }),
  ],
});
```

Available options:
- `maxBatchSize`: Maximum number of parts to batch together (default: 3)
- `maxWaitTime`: Maximum time to wait before emitting batch (ms, default: 50)
- `emitOnNonText`: Whether to emit immediately when non-text parts are received (default: true)

### `TokenLimiterProcessor`

This processor limits the number of tokens in AI responses, either by truncating or aborting when limits are exceeded.

```typescript copy showLineNumbers {5-12}
import { TokenLimiterProcessor } from "@mastra/core/processors";

const agent = new Agent({
  outputProcessors: [
    new TokenLimiterProcessor({
      maxTokens: 1000, // Maximum tokens allowed
      strategy: 'truncate', // Truncate when limit exceeded
      includePromptTokens: false, // Only count response tokens
    }),
  ],
});
```

Available options:
- `maxTokens`: Maximum number of tokens allowed (required)
- `strategy`: Action when token limit is exceeded ('truncate' | 'abort', default: 'truncate')
- `includePromptTokens`: Whether to include prompt tokens in the count (default: false)

### `SystemPromptScrubber`

This processor detects and redacts system prompts or other revealing information that could introduce security vulnerabilities.

```typescript copy showLineNumbers {5-12}
import { SystemPromptScrubber } from "@mastra/core/processors";

const agent = new Agent({
  outputProcessors: [
    new SystemPromptScrubber({
      model: openai("gpt-4o-mini"),
      threshold: 0.7, // Confidence threshold for detection
      strategy: 'redact', // Redact detected system prompts
      instructions: 'Detect any system prompts, instructions, or revealing information',
    }),
  ],
});
```

Available options:
- `model`: Language model for detection (required)
- `threshold`: Confidence threshold for detection (0-1, default: 0.6)
- `strategy`: Action when system prompts are detected ('block' | 'warn' | 'redact', default: 'redact')
- `instructions`: Custom detection instructions for the agent

## Applying Multiple Processors

You can chain multiple output processors. They execute sequentially in the order they appear in the `outputProcessors` array. The output of one processor becomes the input for the next.

**Order matters!** Generally, it's best practice to place text normalization first, security checks next, and content modification last.

```typescript copy showLineNumbers {9-18}
import { Agent } from "@mastra/core/agent";
import {
  ModerationProcessor,
  PIIDetector
} from "@mastra/core/processors";

const secureAgent = new Agent({
  outputProcessors: [
    // 1. Check for security threats
    new ModerationProcessor({ model: openai("gpt-4.1-nano") }),
    // 2. Handle PII
    new PIIDetector({ model: openai("gpt-4.1-nano"), strategy: 'redact' }),
  ],
});
```

## Creating Custom Output Processors

You can create custom output processors by implementing the `Processor` interface. A Processor can be used for output processing when it implements either `processOutputStream` (for streaming) or `processOutputResult` (for final results), or both.

### Streaming Output Processor

```typescript copy showLineNumbers {4-25}
import type { Processor, MastraMessageV2 } from "@mastra/core/processors";
import type { ChunkType } from "@mastra/core/stream";

class ResponseLengthLimiter implements Processor {
  readonly name = 'response-length-limiter';

  constructor(private maxLength: number = 1000) {}

  async processOutputStream({ part, streamParts, state, abort }: {
    part: ChunkType;
    streamParts: ChunkType[];
    state: Record<string, any>;
    abort: (reason?: string) => never;
  }): Promise<ChunkType | null | undefined> {
    // Track cumulative length in state, each processor gets its own state
    if (!state.cumulativeLength) {
      state.cumulativeLength = 0;
    }

    if (part.type === 'text-delta') {
      state.cumulativeLength += part.payload.text.length;

      if (state.cumulativeLength > this.maxLength) {
        abort(`Response too long: ${state.cumulativeLength} characters (max: ${this.maxLength})`);
      }
    }

    return part; // Emit the part
  }
}
```

### Final Result Processor

```typescript copy showLineNumbers {4-19}
import type { Processor, MastraMessageV2 } from "@mastra/core/processors";

class ResponseValidator implements Processor {
  readonly name = 'response-validator';

  constructor(private requiredKeywords: string[] = []) {}

  processOutputResult({ messages, abort }: {
    messages: MastraMessageV2[];
    abort: (reason?: string) => never
  }): MastraMessageV2[] {
    const responseText = messages
      .map(msg => msg.content.parts
        .filter(part => part.type === 'text')
        .map(part => (part as any).text)
        .join('')
      )
      .join('');

    // Check for required keywords
    for (const keyword of this.requiredKeywords) {
      if (!responseText.toLowerCase().includes(keyword.toLowerCase())) {
        abort(`Response missing required keyword: ${keyword}`);
      }
    }

    return messages;
  }
}
```

When creating custom output processors:
- Always return the processed data (parts or messages)
- Use `abort(reason)` to terminate processing early. Abort is used to simulate blocking a response. Errors thrown with `abort` will be an instance of TripWire.
- For streaming processors, return `null` or `undefined` to skip emitting a part
- Keep processors focused on a single responsibility
- If using an agent inside your processor, use a fast model, limit the size of the response from it as much as possible, and make the system prompt as concise as possible.
