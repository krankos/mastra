---
title: "Guardrails | Agents | Mastra Docs"
description: "Learn how to implement guardrails using input and output processors to secure and control AI interactions."
---

# Guardrails

Agents use processors to implement guardrails by intercepting, modifying, validating, or blocking messages at different stages of the AI interaction. Operating on the conversation thread, processors can transform, filter, or abort requests based on defined logic.

Processors can be configured as:

- **`inputProcessors`**: Applied before messages reach the language model.
- **`outputProcessors`**: Applied to responses before they're returned to users.

Processors can be used for content moderation, prompt injection prevention, response sanitization, message transformation, and other security-related controls. Mastra provides several built-in input and output processors for common use cases.

## Adding processors to an agent

Import and instantiate the relevant processor class, and pass it to your agentâ€™s configuration using either the `inputProcessors` or `outputProcessors` parameter:

```typescript {3,9-17} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { ModerationProcessor } from "@mastra/core/processors";

export const agent = new Agent({
  name: "moderated-agent",
  instructions: "You are a helpful assistant",
  model: openai("gpt-4o-mini"),
  inputProcessors: [
    new ModerationProcessor({
      model: openai("gpt-4.1-nano"),
      categories: ["hate", "harassment", "violence"],
      threshold: 0.7,
      strategy: "block",
      instructions: "Detect and flag inappropriate content in user messages",
    })
  ]
});
```

## Input processors

Input processors are applied before user messages reach the language model. They are useful for normalization, validation, content moderation, prompt injection detection, and security checks.

### Normalizing user messages

The `UnicodeNormalizer` is an input processor that cleans and normalizes user input by unifying Unicode characters, standardizing whitespace, and removing problematic symbols, allowing the LLM to better understand user messages.

```typescript {6-9} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { UnicodeNormalizer } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new UnicodeNormalizer({
      stripControlChars: true,
      collapseWhitespace: true,
    })
  ],
});
```

> See [UnicodeNormalizer](../../reference/processors/unicode-normalizer.mdx) for a full list of configuration options.

### Preventing prompt injection

The `PromptInjectionDetector` is an input processor that scans user messages for prompt injection, jailbreak attempts, and system override patterns. It uses an LLM to classify risky input and can block or rewrite it before it reaches the model.

```typescript {6-11} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { PromptInjectionDetector } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new PromptInjectionDetector({
      model: openai("gpt-4.1-nano"),
      threshold: 0.8,
      strategy: 'rewrite',
      detectionTypes: ['injection', 'jailbreak', 'system-override'],
    })
  ],
});
```

> See [PromptInjectionDetector](../../reference/processors/prompt-injection-detector.mdx) for a full list of configuration options.

### Detecting and translating language

The `LanguageDetector` is an input processor that detects and translates user messages into a target language, enabling multilingual support while maintaining consistent interaction. It uses an LLM to identify the language and perform the translation.

```typescript {6-11} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { LanguageDetector } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new LanguageDetector({
      model: openai("gpt-4.1-nano"),
      targetLanguages: ['English', 'en'],
      strategy: 'translate',
      threshold: 0.8,
    })
  ],
});
```

> See [LanguageDetector](../../reference/processors/language-detector.mdx) for a full list of configuration options.

## Hybrid processors

Hybrid processors can be applied either before messages are sent to the language model or before responses are returned to the user. They are useful for tasks like content moderation and PII redaction.

### Moderating input and output

The `ModerationProcessor` is a hybrid processor that detects inappropriate or harmful content across categories like hate, harassment, and violence. It can be used to moderate either user input or model output, depending on where it's applied. It uses an LLM to classify the message and can block or rewrite it based on your configuration.

```typescript {6-11, 14-16} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { ModerationProcessor } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new ModerationProcessor({
      model: openai("gpt-4.1-nano"),
      threshold: 0.7,
      strategy: "block",
      categories: ["hate", "harassment", "violence"]
    })
  ],
  outputProcessors: [
    new ModerationProcessor({
      // ...
    })
  ]
});
```

> See [ModerationProcessor](../../reference/processors/moderation-processor.mdx) for a full list of configuration options.

### Detecting and redacting PII

The `PIIDetector` is a hybrid processor that detects and removes personally identifiable information such as emails, phone numbers, and credit cards. It can redact either user input or model output, depending on where it's applied. It uses an LLM to identify sensitive content based on configured detection types.

```typescript {6-13, 16-18} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { PIIDetector } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new PIIDetector({
      model: openai("gpt-4.1-nano"),
      threshold: 0.6,
      strategy: 'redact',
      redactionMethod: 'mask',
      detectionTypes: ['email', 'phone', 'credit-card'],
      instructions: "Detect and mask personally identifiable information."
    })
  ],
  outputProcessors: [
    new PIIDetector({
      // ...
    })
  ]
});
```

> See [PIIDetector](../../reference/processors/pii-detector.mdx) for a full list of configuration options.

## Output processors

Output processors are applied after the language model generates a response, but before it is returned to the user. They are useful for response optomization, moderation, transformation, and applying safety controls.

### Batching streamed output

The `BatchPartsProcessor` is an output processor that combines multiple stream parts before emitting them to the client. This reduces network overhead and improves the user experience by consolidating small chunks into larger batches.

```typescript {6-10} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { BatchPartsProcessor } from "@mastra/core/processors";

export const agent = new Agent({
  // ...
  outputProcessors: [
    new BatchPartsProcessor({
      batchSize: 5,
      maxWaitTime: 100,
      emitOnNonText: true
    })
  ]
});
```

> See [BatchPartsProcessor](../../reference/processors/batch-parts-processor.mdx) for a full list of configuration options.

### Limiting token usage

The `TokenLimiterProcessor` is an output processor that limits the number of tokens in model responses. It helps manage cost and performance by truncating or blocking messages when the limit is exceeded.

```typescript {6-10, 13-15} filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import { TokenLimiterProcessor } from "@mastra/core/processors";

export const agent = new Agent({
  // ...
  outputProcessors: [
    new TokenLimiterProcessor({
      limit: 1000,
      strategy: "truncate",
      countMode: "cumulative"
    })
  ]
```

> See [TokenLimiterProcessor](../../reference/processors/token-limiter-processor.mdx) for a full list of configuration options.

### Scrubbing system prompts

The `SystemPromptScrubber` is an output processor that detects and redacts system prompts or other internal instructions from model responses. It helps prevent unintended disclosure of prompt content or configuration details that could introduce security risks. It uses an LLM to identify and redact sensitive content based on configured detection types.

```typescript copy showLineNumbers {5-13}
import { SystemPromptScrubber } from "@mastra/core/processors";

const agent = new Agent({
  outputProcessors: [
    new SystemPromptScrubber({
      model: openai("gpt-4.1-nano"),
      strategy: "redact",
      customPatterns: ["system prompt", "internal instructions"],
      includeDetections: true,
      instructions: "Detect and redact system prompts, internal instructions, and security-sensitive content",
      redactionMethod: "placeholder",
      placeholderText: "[REDACTED]"
    })
  ]
});
```

> See [SystemPromptScrubber](../../reference/processors/system-prompt-scrubber.mdx) for a full list of configuration options.

## Applying multiple processors

You can apply multiple processors by listing them in the `inputProcessors` or `outputProcessors` array. They run in sequence, with each processor receiving the output of the one before it.

A typical order might be:

1. **Normalization**: Standardize input format (`UnicodeNormalizer`).
2. **Security checks**: Detect threats or sensitive content (`PromptInjectionDetector`, `PIIDetector`).
3. **Filtering**: Block or transform messages (`ModerationProcessor`).

The order affects behavior, so arrange processors to suit your goals.

```typescript filename="src/mastra/agents/test-agent.ts" showLineNumbers copy
import {
  UnicodeNormalizer,
  ModerationProcessor,
  PromptInjectionDetector,
  PIIDetector
  } from "@mastra/core/processors";

export const testAgent = new Agent({
  // ...
  inputProcessors: [
    new UnicodeNormalizer({
      //...
    }),
    new PromptInjectionDetector({
      // ...
    }),
    new PIIDetector({
      // ...
    }),
    new ModerationProcessor({
      // ...
    })
  ],
});
```

## Understanding aborted requests

If a user message or agent response fails the checks defined by a processor, the request is immediately stopped and no further processors run. The agent still returns a 200 response with details explaining why the request was aborted.

For example, if an agent uses the `PIIDetector` and a `.generate()` or `.stream()` call includes a credit card number:

```typescript
const result = await agent.generate("4543 1374 5089 4332");

console.log(result.text);

const stream = await agent.stream("4543 1374 5089 4332");

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

The response would include a message explaining what was detected and redacted:

```text
[PIIDetector] Redacted PII: PII detected.
Types: credit-card.

Detections: 1 items
```


